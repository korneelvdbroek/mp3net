{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of mp3net.ipynb","private_outputs":true,"provenance":[{"file_id":"1snX5f6qFzot8i-y0mm18PgEEz_OGEDZJ","timestamp":1655454926685},{"file_id":"19yhi36-sMAv9fB9SYCIw7wvBh8IJJ2Fm","timestamp":1602240846970}],"collapsed_sections":[],"authorship_tag":"ABX9TyOKXtfh0agvwYmXlBx/iOE7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["# check location of backend\n","import subprocess\n","import json\n","proc=subprocess.Popen('curl ipinfo.io', shell=True, stdout=subprocess.PIPE, )\n","ip_data = json.loads(proc.communicate()[0])\n","server_country = ip_data['country']\n","print(f\"Server location:   {ip_data['city']} ({ip_data['region']}), {server_country}\\n\")"],"metadata":{"id":"ew8mWwrbzgX1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["project_id = 'YOUR_PROJECT_ID'\n","!gcloud config set project {project_id}\n","\n","# connect to gs://\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","# Connect to Google Drive \n","# The program code is assumed to be on Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Set environment variable so service accounts gets access to bucket (needed for gspath)\n","# (for more info see: https://cloud.google.com/docs/authentication/getting-started)\n","import os\n","os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/content/gdrive/JSON_WITH_SERVICE_ACCOUNT_PRIVATE_KEYS\""],"metadata":{"id":"Yuh4OGTdzjbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### ======================== RUN PARAMETERS ======================= ###\n","###                                                                 ###\n","# dict with bucket-region pairs\n","# script will pick bucket in same region as backend to avoid expensive e-gress charges\n","# when training on TPUs YOUR_BUCKET_REGION should be US since all Colab TPUs are the US region\n","BUCKETS = {'gs://YOUR_BUCKET_NAME/': ['YOUR_BUCKET_REGION']}   \n","\n","# Location and type of source files (on gs://...)\n","DATA_DIR = 'FILEPATH_OF_TFRECORD_FILES' # directory containing .tfrecords dataset (don't prefix with gs://YOUR_BUCKET_NAME)\n","BASE_DIR = 'FILEPATH_FOR_TRAINING'      # directory where training data will be stored (don't prefix with gs://YOUR_BUCKET_NAME)\n","TRAIN_SUB_DIR = ''                      # when empty, code will create a new subdirectory\n","INFER_DIR = './infer/'                  # sub-directory inside BASE_DIR for inference data\n","N_DISCR = 2\n","REPLICA_BATCH = 8\n","###                                                                 ###\n","### =============================================================== ###"],"metadata":{"id":"nQNdTgqXzok1"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KOgv4chUD96S"},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","# select target bucket, based on country of backend (avoid e-gress!!!)\n","target_bucket = None\n","for bucket, country_lst in BUCKETS.items():\n","  if server_country in country_lst:\n","    target_bucket = bucket\n","    break\n","if target_bucket is None: \n","  raise ValueError(f'No target-bucket found for {server_country}')\n","print(f\"Target-bucket:     {target_bucket}\")\n","\n","# add target-bucket to directories\n","DATA_DIR = target_bucket + DATA_DIR\n","BASE_DIR = target_bucket + BASE_DIR"],"metadata":{"id":"9dD1TvKUzoSY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# install modules used by the code\n","!pip install tensorboardx\n","!pip install soundfile\n","!pip install tensorflow_addons"],"metadata":{"id":"TDDD-d2t0uW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UpvbIGaocXEy"},"source":["# install script to profile the TPU. This script is launched from the Python code of the model\n","!pip install --upgrade \"cloud-tpu-profiler>=1.15.0rc1\"\n","\n","# install the tensorboard profile plugin (capture the data via capture-tpu-profile which is launched from the Python code!)\n","!pip install -U tensorboard_plugin_profile\n","\n","# load tensorboard magic\n","%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sF_067aLu25r"},"source":["# Make sure python finds the imports\n","import sys\n","sys.path.append('/content/gdrive/PATH_TO/audiocodec')\n","sys.path.append('/content/gdrive/PATH_TO/mp3net')\n","\n","# local install of audiocodec (only needs to be executed once)\n","!pip install -e /content/gdrive/My\\ Drive/program/MLTrance/audiocodec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGtrgKNCLO6K"},"source":["TRAIN_SUB_DIR = TRAIN_SUB_DIR if TRAIN_SUB_DIR != '' else None\n","NUM_REPLICA = 8\n","from argparse import Namespace\n","args = Namespace(mode='train',\n","                 training_base_dir=BASE_DIR, \n","                 training_sub_dir=TRAIN_SUB_DIR,\n","                 infer_dir=INFER_DIR,\n","                 data_dir=DATA_DIR, \n","                 n_discr=N_DISCR,\n","                 summary_freq=250,\n","                 runtime_tpu=True,\n","                 tpu_profiling=False,\n","                 runtime_eval_process=True, \n","                 runtime_launch_tensorboard=False,\n","                 batch_size=NUM_REPLICA*REPLICA_BATCH, data_shuffle_buffer_size=NUM_REPLICA*REPLICA_BATCH*64, train_checkpoint_freq=200)\n","silent = True\n","\n","import launcher \n","setattr(args, \"training_dir\", launcher.get_training_dir(args, confirm=not silent and (args.mode=='train')))\n","\n","SUMMARY_DIR = f\"{args.training_dir}/summary/\"\n","setattr(args, \"summary_dir\", SUMMARY_DIR)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6UWAtLbdfWXb"},"source":["# Start a TPU\n","# note: all Google colab TPUs in 2019 were located in the US region (https://github.com/googlecolab/colabtools/issues/597)\n","if args.runtime_tpu:\n","  print(\"starting TPU...\")\n","  tpu_strategy = launcher.setup_tpu()\n","else:  \n","  tpu_strategy = None\n","  print(\"GPU information:\")\n","  !nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zk4RBS3K-3mi"},"source":["# run tensorboard (note: keeping tensorboard running implies class A and B operations and hence GSC costs)\n","print(f\"Summary directory = {SUMMARY_DIR}\")\n","%tensorboard --logdir=$SUMMARY_DIR"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_M-bIWlVFhv"},"source":["# ===>>> RUN <<<===\n","import launcher\n","launcher.execute(args, tpu_strategy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"3WH3Q4Ic0uP7"},"execution_count":null,"outputs":[]}]}